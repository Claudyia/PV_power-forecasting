{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Verifica che il progetto sia disponibile in `/content/PV_power-forecasting`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Installa librerie per il training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q torch pandas numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Importa i moduli e prepara i DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/PV_power-forecasting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from split import split_and_scale\n",
        "from dataloader import create_dataloader\n",
        "from gru_model import GRUDirectModel, train_one_epoch, eval_one_epoch, device\n",
        "\n",
        "DATA_FILE = Path('processed/merged_dataset_final_interpolated.xlsx')\n",
        "if not DATA_FILE.exists():\n",
        "    raise FileNotFoundError('Esegui prima il preprocessing/interpolazione.')\n",
        "\n",
        "df = pd.read_excel(DATA_FILE)\n",
        "train_scaled, val_scaled, test_scaled, feature_scaler, target_scaler = split_and_scale(df)\n",
        "\n",
        "TARGET_COL = 'Production_KWh'\n",
        "future_time_cols = ['hour_sin', 'hour_cos', 'doy_sin', 'doy_cos']\n",
        "encoder_cols = [c for c in train_scaled.columns if c not in [TARGET_COL, 'pv_date']]\n",
        "\n",
        "train_dl = create_dataloader(train_scaled, encoder_cols, future_time_cols,\n",
        "                             input_length=168, forecast_horizon=24,\n",
        "                             batch_size=32, shuffle=True)\n",
        "val_dl = create_dataloader(val_scaled, encoder_cols, future_time_cols,\n",
        "                           input_length=168, forecast_horizon=24,\n",
        "                           batch_size=32, shuffle=False)\n",
        "test_dl = create_dataloader(test_scaled, encoder_cols, future_time_cols,\n",
        "                            input_length=168, forecast_horizon=24,\n",
        "                            batch_size=1, shuffle=False)\n",
        "\n",
        "len(train_dl), len(val_dl), len(test_dl)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Addestra la GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GRUDirectModel(\n",
        "    enc_in_dim=len(encoder_cols),\n",
        "    future_time_dim=len(future_time_cols),\n",
        "    hidden_dim=128,\n",
        "    num_layers=2,\n",
        "    forecast_horizon=24\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "EPOCHS = 20\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = train_one_epoch(model, train_dl, optimizer, device)\n",
        "    val_loss = eval_one_epoch(model, val_dl, device)\n",
        "    print(f'Epoch {epoch:02d} | Train {train_loss:.4f} | Val {val_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Crea la previsione finale e salva su CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for x_enc, x_future, y in test_dl:\n",
        "        x_enc, x_future = x_enc.to(device), x_future.to(device)\n",
        "        pred_scaled = model(x_enc, x_future).cpu().numpy()[0]\n",
        "        all_predictions.append(pred_scaled)\n",
        "\n",
        "last_pred_scaled = np.array(all_predictions[-1]).reshape(-1, 1)\n",
        "last_pred = target_scaler.inverse_transform(last_pred_scaled).flatten()\n",
        "\n",
        "last_timestamp = df.index[-1]\n",
        "future_times = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1),\n",
        "                             periods=24, freq='H')\n",
        "\n",
        "df_pred = pd.DataFrame({'timestamp': future_times, 'pv_forecast': last_pred})\n",
        "output_path = Path('predictions_colab.csv')\n",
        "df_pred.to_csv(output_path, index=False)\n",
        "print('âœ“ Salvato', output_path)\n",
        "df_pred.head()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
