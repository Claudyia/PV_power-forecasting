{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd6be18",
   "metadata": {},
   "source": [
    "import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51ebca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Controllo ambiente Python / Colab / PyTorch...\n",
      "--------------------------------------------------\n",
      "‚û°Ô∏è Versione Python rilevata: 3.12.12\n",
      "\n",
      "‚ùå PyTorch NON √® compatibile con Python 3.12.\n",
      "‚ùå Colab ha aggiornato il runtime a Python 3.12, che PyTorch NON supporta.\n",
      "\n",
      "üî• Soluzione: usa Colab Legacy (Python 3.10):\n",
      "üëâ https://colab.research.google.com/?runtime=python3.10\n",
      "\n",
      "üìå Dopo aver aperto Colab Legacy, installa PyTorch con:\n",
      "!pip install torch==2.2.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to override a python impl for DispatchKey.Meta on operator aten::broadcast_tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2875220848.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2680\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from torch._decomp import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0m_convert_out_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;31m# populate the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_refs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDispatchKey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompositeImplicitAutograd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2785\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDispatchKey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2786\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorLikeType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_kernels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    153\u001b[0m                     \u001b[0;34mf\"Trying to override a python impl for {k} on operator {self.name()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to override a python impl for DispatchKey.Meta on operator aten::broadcast_tensors"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "\n",
    "print(\"üîç Controllo ambiente Python / Colab / PyTorch...\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# VERSIONE PYTHON\n",
    "py_ver = sys.version.split(\" \")[0]\n",
    "major, minor, _ = py_ver.split(\".\")\n",
    "\n",
    "print(f\"‚û°Ô∏è Versione Python rilevata: {py_ver}\")\n",
    "\n",
    "# CONTROLLO VERSIONE COMPATIBILE PYTORCH\n",
    "supported_minor = [\"8\", \"9\", \"10\", \"11\"]  # Python 3.8‚Äì3.11\n",
    "is_supported = minor in supported_minor\n",
    "\n",
    "if not is_supported:\n",
    "    print(\"\\n‚ùå PyTorch NON √® compatibile con Python 3.12.\")\n",
    "    print(\"‚ùå Colab ha aggiornato il runtime a Python 3.12, che PyTorch NON supporta.\")\n",
    "    print(\"\\nüî• Soluzione: usa Colab Legacy (Python 3.10):\")\n",
    "    print(\"üëâ https://colab.research.google.com/?runtime=python3.10\")\n",
    "    print(\"\\nüìå Dopo aver aperto Colab Legacy, installa PyTorch con:\")\n",
    "    print(\"!pip install torch==2.2.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Puoi installare PyTorch normalmente.\")\n",
    "    print(\"Esempio (GPU):\")\n",
    "    print(\"!pip install torch==2.2.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "    print(\"\\nOppure (CPU only):\")\n",
    "    print(\"!pip install torch==2.2.0 --index-url https://download.pytorch.org/whl/cpu\")\n",
    "\n",
    "    #------------\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "try:\n",
    "    NOTEBOOK_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    NOTEBOOK_DIR = Path.cwd().resolve()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for path in [start, *start.parents]:\n",
    "        raw = path / \"raw_data\"\n",
    "        processed = path / \"processed\"\n",
    "        if raw.exists() and processed.exists():\n",
    "            return path\n",
    "    raise FileNotFoundError(f\"raw_data/processed non trovate partendo da {start}\")\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/pv_project\")\n",
    "DATA_DIR = PROJECT_ROOT / \"raw_data\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"processed\"\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROJECT_ROOT = Path(\"/content/PV_power-forecasting\")\n",
    "\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178bf7a1",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46233d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD PV\n",
    "# ============================================================\n",
    "\n",
    "def load_pv():\n",
    "    pv_excel = DATA_DIR / \"pv_dataset.xlsx\"\n",
    "\n",
    "    pv1 = pd.read_excel(pv_excel, sheet_name=0)\n",
    "    pv2 = pd.read_excel(pv_excel, sheet_name=1)\n",
    "    pv = pd.concat([pv1, pv2], ignore_index=True)\n",
    "\n",
    "    timestamp_col = \"Max kWp\"\n",
    "    value_col = [c for c in pv.columns if c != timestamp_col][0]\n",
    "\n",
    "    pv = pv.rename(columns={\n",
    "        timestamp_col: \"pv_date\",\n",
    "        value_col: \"Production_KWh\"\n",
    "    })\n",
    "\n",
    "    pv[\"pv_date\"] = pd.to_datetime(pv[\"pv_date\"], format=\"mixed\", errors=\"coerce\")\n",
    "    pv = pv.sort_values(\"pv_date\").reset_index(drop=True)\n",
    "\n",
    "    return pv[[\"pv_date\", \"Production_KWh\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. LOAD WX\n",
    "# ============================================================\n",
    "\n",
    "def load_wx():\n",
    "    wx_excel = DATA_DIR / \"wx_dataset.xlsx\"\n",
    "\n",
    "    wx1 = pd.read_excel(wx_excel, sheet_name=0)\n",
    "    wx2 = pd.read_excel(wx_excel, sheet_name=1)\n",
    "    wx = pd.concat([wx1, wx2], ignore_index=True)\n",
    "\n",
    "    wx = wx.rename(columns={\n",
    "        \"dt_iso\": \"wx_date\",\n",
    "        \"temp\": \"temperature\"\n",
    "    })\n",
    "\n",
    "    def safe_parse(x):\n",
    "        try:\n",
    "            dt = parser.parse(str(x))\n",
    "            if dt.tzinfo is not None:\n",
    "                dt = dt.replace(tzinfo=None)\n",
    "            return dt\n",
    "        except:\n",
    "            return pd.NaT\n",
    "\n",
    "    wx[\"wx_date\"] = wx[\"wx_date\"].apply(safe_parse)\n",
    "    wx[\"wx_date\"] = pd.to_datetime(wx[\"wx_date\"], errors=\"coerce\")\n",
    "    wx = wx.dropna(subset=[\"wx_date\"])\n",
    "    wx = wx.sort_values(\"wx_date\").reset_index(drop=True)\n",
    "\n",
    "    return wx\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. FIX WX TIMELINE\n",
    "# ============================================================\n",
    "\n",
    "def fix_daily_wx_timeline(wx: pd.DataFrame, start_date) -> pd.DataFrame:\n",
    "    wx = wx.sort_values(\"wx_date\").reset_index(drop=True)\n",
    "\n",
    "    start = pd.to_datetime(start_date, errors=\"coerce\")\n",
    "    start = start.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "    n = len(wx)\n",
    "    new_dates = pd.date_range(start=start, periods=n, freq=\"h\")\n",
    "\n",
    "    wx = wx.copy()\n",
    "    wx[\"wx_date\"] = new_dates\n",
    "    return wx\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. WEATHER CATEGORY\n",
    "# ============================================================\n",
    "\n",
    "def categorize_weather(wx):\n",
    "    def map_weather(desc):\n",
    "        d = str(desc).lower()\n",
    "\n",
    "        if \"broken\" in d or \"overcast\" in d:\n",
    "            return \"cloudy\"\n",
    "        if \"scattered\" in d or \"few\" in d:\n",
    "            return \"partly_cloudy\"\n",
    "        if \"light rain\" in d or \"moderate rain\" in d:\n",
    "            return \"rain\"\n",
    "        if \"clear sky\" in d or d.strip() == \"clear\":\n",
    "            return \"clear\"\n",
    "        return \"other\"\n",
    "\n",
    "    wx[\"weather_category\"] = wx[\"weather_description\"].apply(map_weather)\n",
    "    return wx\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. ONE-HOT ENCODING\n",
    "# ============================================================\n",
    "\n",
    "def one_hot_encode_weather(wx):\n",
    "    dummies = pd.get_dummies(wx[\"weather_category\"], prefix=\"weather\")\n",
    "\n",
    "    expected = [\n",
    "        \"weather_cloudy\",\n",
    "        \"weather_partly_cloudy\",\n",
    "        \"weather_rain\",\n",
    "        \"weather_clear\",\n",
    "        \"weather_other\"\n",
    "    ]\n",
    "    for col in expected:\n",
    "        if col not in dummies:\n",
    "            dummies[col] = 0\n",
    "\n",
    "    return pd.concat([wx, dummies[expected]], axis=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. DROP UNUSED WX COLUMNS\n",
    "# ============================================================\n",
    "\n",
    "def drop_unused_columns(wx):\n",
    "    cols = [\n",
    "        \"lat\", \"lon\", \"dew_point\", \"pressure\",\n",
    "        \"weather_description\"\n",
    "    ]\n",
    "    return wx.drop(columns=[c for c in cols if c in wx.columns])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. TIME FEATURES + LAG + ROLLING\n",
    "# ============================================================\n",
    "\n",
    "def add_time_features(df, date_col):\n",
    "    dt = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "    df[\"month\"] = dt.dt.month\n",
    "    df[\"day\"] = dt.dt.day\n",
    "    df[\"hour\"] = dt.dt.hour\n",
    "    df[\"day_of_week\"] = dt.dt.dayofweek\n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"].isin([5,6]).astype(int)\n",
    "    df[\"day_of_year\"] = dt.dt.dayofyear\n",
    "\n",
    "    df[\"hour_sin\"] = np.sin(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"hour_cos\"] = np.cos(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"doy_sin\"] = np.sin(2*np.pi*df[\"day_of_year\"]/366)\n",
    "    df[\"doy_cos\"] = np.cos(2*np.pi*df[\"day_of_year\"]/366)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_lag_features(df, columns, lags):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        for lag in lags:\n",
    "            df[f\"{col}_lag_{lag}h\"] = df[col].shift(lag)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_rolling_features(df, columns, windows):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        for w in windows:\n",
    "            df[f\"{col}_roll_mean_{w}h\"] = df[col].rolling(w).mean()\n",
    "            df[f\"{col}_roll_max_{w}h\"] = df[col].rolling(w).max()\n",
    "            df[f\"{col}_roll_min_{w}h\"] = df[col].rolling(w).min()\n",
    "            df[f\"{col}_roll_std_{w}h\"] = df[col].rolling(w).std()\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_weather_combinations(df):\n",
    "    df = df.copy()\n",
    "    ghi_col = next((c for c in [\"GHI\",\"Ghi\",\"ghi\"] if c in df.columns), None)\n",
    "\n",
    "    if ghi_col and \"weather_cloudy\" in df.columns:\n",
    "        df[\"effective_radiation\"] = df[ghi_col] * (1 - df[\"weather_cloudy\"])\n",
    "    if ghi_col and \"temperature\" in df.columns:\n",
    "        df[\"ghi_temp_ratio\"] = df[ghi_col] / df[\"temperature\"].replace(0, np.nan)\n",
    "    if \"humidity\" in df.columns and \"temperature\" in df.columns:\n",
    "        df[\"rh_temp_product\"] = df[\"humidity\"] * df[\"temperature\"]\n",
    "    if \"wind_speed\" in df.columns and \"temperature\" in df.columns:\n",
    "        df[\"wind_chill_effect\"] = df[\"wind_speed\"] * df[\"temperature\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. MERGE\n",
    "# ============================================================\n",
    "\n",
    "def nuovo_dataset(pv, wx):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"pv_date\"] = pv[\"pv_date\"]\n",
    "    df[\"Production_KWh\"] = pv[\"Production_KWh\"]\n",
    "\n",
    "    for col in [\"temperature\", \"humidity\", \"Ghi\", \"Dhi\", \"Dni\", \"wind_speed\", \"clouds_all\"]:\n",
    "        if col in wx.columns:\n",
    "            df[col] = wx[col]\n",
    "\n",
    "    for col in [\"weather_cloudy\",\"weather_partly_cloudy\",\"weather_rain\",\"weather_clear\",\"weather_other\"]:\n",
    "        df[col] = wx[col]\n",
    "\n",
    "    for col in [\"hour_sin\",\"hour_cos\",\"doy_sin\",\"doy_cos\"]:\n",
    "        df[col] = pv[col]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. BUILD MERGED DATASET (main function)\n",
    "# ============================================================\n",
    "\n",
    "def build_merged_dataset():\n",
    "    pv = load_pv()\n",
    "    wx = load_wx()\n",
    "\n",
    "    wx = categorize_weather(wx)\n",
    "    wx = one_hot_encode_weather(wx)\n",
    "    wx = drop_unused_columns(wx)\n",
    "\n",
    "    wx = fix_daily_wx_timeline(wx, start_date=pv[\"pv_date\"].iloc[0])\n",
    "    pv = add_time_features(pv, date_col=\"pv_date\")\n",
    "\n",
    "    merged = nuovo_dataset(pv, wx)\n",
    "\n",
    "    merged = add_lag_features(merged, [\"Production_KWh\"], [1,12,24])\n",
    "    merged = add_rolling_features(merged, [\"Production_KWh\"], [3,6,24])\n",
    "    merged = add_weather_combinations(merged)\n",
    "\n",
    "    history = 24\n",
    "    merged = merged.iloc[history:].reset_index(drop=True)\n",
    "\n",
    "    out = OUTPUT_DIR / \"merged_dataset_final.xlsx\"\n",
    "    merged.to_excel(out, index=False)\n",
    "    print(\"‚úì merged_dataset_final.xlsx salvato.\")\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa66efe",
   "metadata": {},
   "source": [
    "cosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# OUTLIER HANDLING\n",
    "# ==========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\".\")\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"processed\"\n",
    "PROCESSED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MERGED_CLEAN_UNIFIED = PROCESSED_DIR / \"merged_dataset_final.xlsx\"\n",
    "OUTPUT_INTERPOLATED = PROCESSED_DIR / \"merged_dataset_final_interpolated.xlsx\"\n",
    "\n",
    "\n",
    "def find_outliers(df, column=\"Production_KWh\", ghi_column=\"Ghi\",\n",
    "                  q_factor=1.20, ghi_ratio=0.25):\n",
    "\n",
    "    prod = df[column]\n",
    "    has_ghi = ghi_column in df.columns\n",
    "    ghi = df[ghi_column] if has_ghi else None\n",
    "\n",
    "    q75 = prod.quantile(0.75)\n",
    "    threshold_q = q75 * q_factor\n",
    "\n",
    "    mask = prod > threshold_q\n",
    "    if has_ghi:\n",
    "        mask |= (prod > ghi * ghi_ratio)\n",
    "\n",
    "    df_outliers = df[mask]\n",
    "    return df_outliers, mask\n",
    "\n",
    "\n",
    "def interpolate_point_by_point(df, mask, column=\"Production_KWh\"):\n",
    "    df_fixed = df.copy()\n",
    "    idxs = np.where(mask)[0]\n",
    "\n",
    "    for i in idxs:\n",
    "        prev = df_fixed[column].iloc[i-1] if i > 0 else None\n",
    "        nex  = df_fixed[column].iloc[i+1] if i < len(df_fixed)-1 else None\n",
    "\n",
    "        if prev is not None and nex is not None:\n",
    "            df_fixed.at[i, column] = (prev + nex) / 2\n",
    "        elif prev is not None:\n",
    "            df_fixed.at[i, column] = prev\n",
    "        elif nex is not None:\n",
    "            df_fixed.at[i, column] = nex\n",
    "\n",
    "    return df_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f9a16",
   "metadata": {},
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SPLIT AND SCALE\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def split_and_scale(df, target_col=\"Production_KWh\",\n",
    "                    time_cols=[\"hour_sin\",\"hour_cos\",\"doy_sin\",\"doy_cos\"],\n",
    "                    train_ratio=0.6, val_ratio=0.2):\n",
    "\n",
    "    n = len(df)\n",
    "    train_size = int(n * train_ratio)\n",
    "    val_size = int(n * val_ratio)\n",
    "\n",
    "    train_df = df.iloc[:train_size]\n",
    "    val_df   = df.iloc[train_size : train_size + val_size]\n",
    "    test_df  = df.iloc[train_size + val_size :]\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    feature_cols = [c for c in df.columns if c not in {target_col,\"pv_date\"}]\n",
    "    scale_cols = [c for c in feature_cols if c in numeric_cols and c not in time_cols]\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    target_scaler  = StandardScaler()\n",
    "\n",
    "    train_scaled_block = feature_scaler.fit_transform(train_df[scale_cols])\n",
    "    val_scaled_block   = feature_scaler.transform(val_df[scale_cols])\n",
    "    test_scaled_block  = feature_scaler.transform(test_df[scale_cols])\n",
    "\n",
    "    y_train = target_scaler.fit_transform(train_df[[target_col]])\n",
    "    y_val   = target_scaler.transform(val_df[[target_col]])\n",
    "    y_test  = target_scaler.transform(test_df[[target_col]])\n",
    "\n",
    "    def rebuild(df_orig, scaled_block, y_scaled):\n",
    "        out = df_orig.copy()\n",
    "        out[scale_cols] = scaled_block\n",
    "        out[target_col] = y_scaled\n",
    "        return out\n",
    "\n",
    "    return (\n",
    "        rebuild(train_df, train_scaled_block, y_train),\n",
    "        rebuild(val_df, val_scaled_block, y_val),\n",
    "        rebuild(test_df, test_scaled_block, y_test),\n",
    "        feature_scaler,\n",
    "        target_scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d66bdb",
   "metadata": {},
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e26dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# DATALOADER\n",
    "# ==========================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GRUDirectDataset(Dataset):\n",
    "    def __init__(self, df,\n",
    "                 input_length=168,\n",
    "                 forecast_horizon=24,\n",
    "                 target_col=\"Production_KWh\",\n",
    "                 encoder_cols=None,\n",
    "                 future_time_cols=None):\n",
    "\n",
    "        self.df = df\n",
    "        self.input_length = input_length\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.target_col = target_col\n",
    "        self.encoder_cols = encoder_cols\n",
    "        self.future_time_cols = future_time_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.input_length - self.forecast_horizon\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_enc = self.df.iloc[idx : idx+self.input_length][self.encoder_cols].values.astype(\"float32\")\n",
    "\n",
    "        x_future = self.df.iloc[\n",
    "            idx+self.input_length : idx+self.input_length+self.forecast_horizon\n",
    "        ][self.future_time_cols].values.astype(\"float32\")\n",
    "\n",
    "        y = self.df.iloc[\n",
    "            idx+self.input_length : idx+self.input_length+self.forecast_horizon\n",
    "        ][self.target_col].values.astype(\"float32\")\n",
    "\n",
    "        return torch.tensor(x_enc), torch.tensor(x_future), torch.tensor(y)\n",
    "\n",
    "\n",
    "def create_dataloader(df, encoder_cols, future_time_cols,\n",
    "                      input_length=168, forecast_horizon=24,\n",
    "                      batch_size=32, shuffle=True,\n",
    "                      target_col=\"Production_KWh\"):\n",
    "\n",
    "    dataset = GRUDirectDataset(\n",
    "        df=df,\n",
    "        input_length=input_length,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        encoder_cols=encoder_cols,\n",
    "        future_time_cols=future_time_cols,\n",
    "        target_col=target_col\n",
    "    )\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32a975",
   "metadata": {},
   "source": [
    "gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa77ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# GRU MODEL + TRAINING\n",
    "# ==========================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from split import split_and_scale\n",
    "from dataloader import create_dataloader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class GRUDirectModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 enc_in_dim,\n",
    "                 future_time_dim=4,\n",
    "                 hidden_dim=128,\n",
    "                 num_layers=2,\n",
    "                 forecast_horizon=24):\n",
    "        super().__init__()\n",
    "\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "\n",
    "        self.encoder = nn.GRU(\n",
    "            input_size=enc_in_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + future_time_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_future):\n",
    "        _, h = self.encoder(x_enc)\n",
    "        h_last = h[-1]\n",
    "\n",
    "        h_rep = h_last.unsqueeze(1).repeat(1, self.forecast_horizon, 1)\n",
    "        fused = torch.cat([h_rep, x_future], dim=-1)\n",
    "\n",
    "        return self.mlp(fused).squeeze(-1)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    tot = 0\n",
    "    for x_enc, x_fut, y in loader:\n",
    "        x_enc, x_fut, y = x_enc.to(device), x_fut.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_enc, x_fut)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tot += loss.item()\n",
    "    return tot / len(loader)\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    tot = 0\n",
    "    with torch.no_grad():\n",
    "        for x_enc, x_fut, y in loader:\n",
    "            x_enc, x_fut, y = x_enc.to(device), x_fut.to(device), y.to(device)\n",
    "            pred = model(x_enc, x_fut)\n",
    "            tot += criterion(pred, y).item()\n",
    "    return tot / len(loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
